{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (1.2.7)\n",
      "Requirement already satisfied: lightgbm in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (4.5.0)\n",
      "Requirement already satisfied: xgboost in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: graphviz in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (2.0.2)\n",
      "Requirement already satisfied: scipy in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/ia4118/anaconda3/envs/data_science/lib/python3.11/site-packages (from plotly->catboost) (9.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost lightgbm xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Canada': {'2010': 47560.6666009406, '2011': 52223.8588398531, '2012': 52670.3447335415, '2013': 52638.1187235237, '2014': 50960.8431174661, '2015': 43594.1941045394, '2016': 42314.0615817218, '2017': 45129.628116623, '2018': 46539.1761570405, '2019': 46352.8693445211, '2020': 43537.839298904, '2021': 52496.8441693242, '2022': 55509.393176404, '2023': 53431.1857063879}, 'Finland': {'2010': 46506.2919016566, '2011': 51060.3242589767, '2012': 47551.6740841369, '2013': 49691.0145200739, '2014': 50073.7760815871, '2015': 42560.3456767103, '2016': 43451.2562442158, '2017': 46085.0174739036, '2018': 49654.2497035329, '2019': 48358.1807773701, '2020': 48828.6846862799, '2021': 53099.1351400148, '2022': 50438.4753952355, '2023': 52925.6897638424}, 'Italy': {'2010': 36184.7118698678, '2011': 38851.3881339353, '2012': 35235.7989058242, '2013': 35747.707952689, '2014': 35750.7197500382, '2015': 30387.1293187854, '2016': 31126.3246947273, '2017': 32554.14668453, '2018': 34746.3441392416, '2019': 33812.788724868, '2020': 32091.4866621366, '2021': 36852.5425414951, '2022': 35635.7442204098, '2023': 39003.3160954123}, 'Kenya': {'2010': 1091.51873101194, '2011': 1096.14499807675, '2012': 1285.00536171512, '2013': 1370.87885214659, '2014': 1482.81566253497, '2015': 1489.11959777284, '2016': 1554.12610314423, '2017': 1667.48447230835, '2018': 1836.45275528993, '2019': 1960.40808854893, '2020': 1927.66459027849, '2021': 2061.35622089594, '2022': 2109.56288513137, '2023': 1952.30457929636}, 'Norway': {'2010': 88163.2085931423, '2011': 101221.813476644, '2012': 102175.919298374, '2013': 103553.840134417, '2014': 97666.6951838749, '2015': 74809.9658049898, '2016': 70867.3609970749, '2017': 76131.8384032764, '2018': 82792.8427113304, '2019': 76430.5889473338, '2020': 68340.0181033702, '2021': 93072.8925119571, '2022': 108798.451165901, '2023': 87925.0944188399}, 'Singapore': {'2010': 47236.683084953, '2011': 53891.4570264372, '2012': 55547.5553077786, '2013': 56967.4257940383, '2014': 57564.8023114977, '2015': 55645.6068614606, '2016': 56899.9181805173, '2017': 61162.0973932771, '2018': 66840.6373389791, '2019': 66081.7199235165, '2020': 61466.803676358, '2021': 79601.4129622433, '2022': 88428.7024226232, '2023': 84734.2559206054}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Specify the countries and indicator\n",
    "countries = \"CAN;FIN;ITA;KEN;NOR;SGP\"  # ISO codes for Canada, Finland, Italy, Kenya, Norway, Singapore\n",
    "indicator = \"NY.GDP.PCAP.CD\"  # GDP per capita (current US$)\n",
    "years = [\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\",\"2021\",\"2022\",\"2023\"]\n",
    "\n",
    "gdp_data = {}\n",
    "\n",
    "for year in years:\n",
    "        \n",
    "    url = f\"https://api.worldbank.org/v2/country/{countries}/indicator/{indicator}?format=json&date={year}\"\n",
    "    # Fetch the data\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract relevant data\n",
    "    for entry in data[1]:\n",
    "        country = entry['country']['value']\n",
    "        gdp_per_capita = entry['value']\n",
    "        year = entry['date']\n",
    "        if country not in gdp_data:\n",
    "            gdp_data[country] = {}\n",
    "            gdp_data[country][year] = gdp_per_capita\n",
    "        else:\n",
    "            if year not in gdp_data[country]:\n",
    "                gdp_data[country][year] = gdp_per_capita\n",
    "\n",
    "\n",
    "print(gdp_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Canada' 'Finland' 'Italy' 'Kenya' 'Norway' 'Singapore']\n",
      "Train data\n",
      "  country              store             product  num_sold  is_weekend  \\\n",
      "1  Canada  Discount Stickers              Kaggle     973.0       False   \n",
      "2  Canada  Discount Stickers        Kaggle Tiers     906.0       False   \n",
      "3  Canada  Discount Stickers            Kerneler     423.0       False   \n",
      "4  Canada  Discount Stickers  Kerneler Dark Mode     491.0       False   \n",
      "5  Canada  Stickers for Less   Holographic Goose     300.0       False   \n",
      "\n",
      "   sin_dayofweek  cos_dayofweek  sin_month  cos_month  sin_year  cos_year  \\\n",
      "1      -0.433884      -0.900969        0.0        1.0       0.0       1.0   \n",
      "2      -0.433884      -0.900969        0.0        1.0       0.0       1.0   \n",
      "3      -0.433884      -0.900969        0.0        1.0       0.0       1.0   \n",
      "4      -0.433884      -0.900969        0.0        1.0       0.0       1.0   \n",
      "5      -0.433884      -0.900969        0.0        1.0       0.0       1.0   \n",
      "\n",
      "   gdp_per_capita  \n",
      "1    47560.666601  \n",
      "2    47560.666601  \n",
      "3    47560.666601  \n",
      "4    47560.666601  \n",
      "5    47560.666601  \n",
      "Test data\n",
      "       id country              store             product  is_weekend  \\\n",
      "0  230130  Canada  Discount Stickers   Holographic Goose        True   \n",
      "1  230131  Canada  Discount Stickers              Kaggle        True   \n",
      "2  230132  Canada  Discount Stickers        Kaggle Tiers        True   \n",
      "3  230133  Canada  Discount Stickers            Kerneler        True   \n",
      "4  230134  Canada  Discount Stickers  Kerneler Dark Mode        True   \n",
      "\n",
      "   sin_dayofweek  cos_dayofweek  sin_month  cos_month  sin_year  cos_year  \\\n",
      "0      -0.781831        0.62349        0.0        1.0 -0.951057 -0.309017   \n",
      "1      -0.781831        0.62349        0.0        1.0 -0.951057 -0.309017   \n",
      "2      -0.781831        0.62349        0.0        1.0 -0.951057 -0.309017   \n",
      "3      -0.781831        0.62349        0.0        1.0 -0.951057 -0.309017   \n",
      "4      -0.781831        0.62349        0.0        1.0 -0.951057 -0.309017   \n",
      "\n",
      "   gdp_per_capita  \n",
      "0    45129.628117  \n",
      "1    45129.628117  \n",
      "2    45129.628117  \n",
      "3    45129.628117  \n",
      "4    45129.628117  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def compute_gdp_per_capita(X,gdp_data):\n",
    "    def get_gdp(row):\n",
    "        country = str(row[\"country\"])\n",
    "        year = str(int(row[\"year\"])+2010)\n",
    "        return gdp_data[country][year]\n",
    "    X[\"gdp_per_capita\"] = X.apply(get_gdp, axis=1)\n",
    "    return X\n",
    "\n",
    "def generate_features(X, train=False):\n",
    "    X = X.copy()\n",
    "        \n",
    "    if train:\n",
    "        X = X.dropna(subset=[\"num_sold\"])\n",
    "        X = X.drop(columns=[\"id\"])\n",
    "\n",
    "    X[\"date\"] = pd.to_datetime(X[\"date\"], format=\"%Y-%m-%d\")\n",
    "    X[\"dayofweek\"] = X[\"date\"].dt.dayofweek\n",
    "    X[\"month\"] = X[\"date\"].dt.month - 1\n",
    "    X[\"year\"] = X[\"date\"].dt.year - 2010\n",
    "    X[\"is_weekend\"] = X[\"dayofweek\"].isin([5,6])\n",
    "    X[\"sin_dayofweek\"] = np.sin(X[\"dayofweek\"] * (2 * np.pi / 7))\n",
    "    X[\"cos_dayofweek\"] = np.cos(X[\"dayofweek\"] * (2 * np.pi / 7))\n",
    "    X[\"sin_month\"] = np.sin(X[\"month\"] * (2 * np.pi / 12))\n",
    "    X[\"cos_month\"] = np.cos(X[\"month\"] * (2 * np.pi / 12))\n",
    "    X[\"sin_year\"] = np.sin(X[\"year\"] * (2 * np.pi / 10))\n",
    "    X[\"cos_year\"] = np.cos(X[\"year\"] * (2 * np.pi / 10))\n",
    "    \n",
    "    X = compute_gdp_per_capita(X,gdp_data)\n",
    "    \n",
    "    X = X.drop(columns=[\"date\",\"month\",\"year\",\"dayofweek\"])\n",
    "        \n",
    "    return X\n",
    "\n",
    "FOLDER = \"playground-series-s5e1/\"\n",
    "train_data = pd.read_csv(FOLDER + \"train.csv\")\n",
    "test_data = pd.read_csv(FOLDER + \"test.csv\")\n",
    "\n",
    "print(train_data[\"country\"].unique())\n",
    "train_data = generate_features(train_data,train=True)\n",
    "test_data = generate_features(test_data)\n",
    "\n",
    "print(\"Train data\")\n",
    "print(train_data.head())\n",
    "print(\"Test data\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating xgb\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m     X_train_fold \u001b[38;5;241m=\u001b[39m prepare_data_lgbm(X_train_fold)\n\u001b[1;32m     93\u001b[0m     X_val_fold \u001b[38;5;241m=\u001b[39m prepare_data_lgbm(X_val_fold)\n\u001b[0;32m---> 95\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)    \n\u001b[1;32m     97\u001b[0m mape \u001b[38;5;241m=\u001b[39m mean_absolute_percentage_error(y_val_fold, y_pred_val)\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/xgboost/sklearn.py:1108\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1105\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m-> 1108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/data_science/lib/python3.11/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "X = train_data.drop(columns=['num_sold'])\n",
    "y = train_data['num_sold']\n",
    "\n",
    "cat_cols = ['country', 'store', 'product']\n",
    "num_cols = [\"sin_dayofweek\", \"cos_dayofweek\", \"sin_month\", \"cos_month\", \"sin_year\", \"cos_year\",\"gdp_per_capita\"]\n",
    "\n",
    "# Create different preprocessors for different models\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For models that need one-hot encoding (XGBoost, RandomForest)\n",
    "categorical_transformer_ohe = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create different preprocessors\n",
    "preprocessor_ohe = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer_ohe, cat_cols)\n",
    "])\n",
    "\n",
    "# For LightGBM and CatBoost, we'll just scale numerics and pass categoricals as is\n",
    "preprocessor_native = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols)\n",
    "])\n",
    "\n",
    "# Define models with appropriate parameters\n",
    "models = {\n",
    "    'xgb': (XGBRegressor(\n",
    "        n_estimators=5000,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    ), preprocessor_ohe),\n",
    "    \n",
    "    'lgbm': (LGBMRegressor(\n",
    "        n_estimators=5000,\n",
    "        learning_rate=0.1,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    ), preprocessor_native),\n",
    "    \n",
    "    'catboost': (CatBoostRegressor(\n",
    "        n_estimators=5000,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        subsample=0.8,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    ), preprocessor_native)\n",
    "}\n",
    "\n",
    "# Create pipelines for each model\n",
    "model_pipelines = {\n",
    "    name: Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ]) for name, (model, preprocessor) in models.items()\n",
    "}\n",
    "\n",
    "# For LightGBM, we need to ensure categorical columns are the right type\n",
    "def prepare_data_lgbm(X):\n",
    "    X = X.copy()\n",
    "    for col in cat_cols:\n",
    "        X[col] = X[col].astype('category')\n",
    "    return X\n",
    "\n",
    "# Modified evaluation loop\n",
    "time_series = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for model_name, pipeline in model_pipelines.items():\n",
    "    print(f\"\\nEvaluating {model_name}\")\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold_index, (train_index, val_index) in enumerate(time_series.split(X)):\n",
    "        X_train_fold = X.iloc[train_index]\n",
    "        y_train_fold = y.iloc[train_index]\n",
    "        X_val_fold = X.iloc[val_index]\n",
    "        y_val_fold = y.iloc[val_index]\n",
    "        \n",
    "        # Special handling for LightGBM\n",
    "        if model_name == 'lgbm':\n",
    "            X_train_fold = prepare_data_lgbm(X_train_fold)\n",
    "            X_val_fold = prepare_data_lgbm(X_val_fold)\n",
    "        \n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_val = pipeline.predict(X_val_fold)    \n",
    "        mape = mean_absolute_percentage_error(y_val_fold, y_pred_val)\n",
    "        fold_scores.append(mape)\n",
    "        print(f\"Fold {fold_index + 1} MAPE: {mape:.4f}\")\n",
    "    \n",
    "    print(f\"Average MAPE for {model_name}: {np.mean(fold_scores):.4f}\")\n",
    "\n",
    "# Train final model\n",
    "best_model_name = min(model_pipelines.keys(), \n",
    "                     key=lambda k: np.mean([mean_absolute_percentage_error(y.iloc[val_idx], \n",
    "                     model_pipelines[k].fit(X.iloc[train_idx], y.iloc[train_idx]).predict(X.iloc[val_idx])) \n",
    "                     for train_idx, val_idx in time_series.split(X)]))\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name}\")\n",
    "\n",
    "# Train the best model on full dataset\n",
    "best_pipeline = model_pipelines[best_model_name]\n",
    "if best_model_name == 'lgbm':\n",
    "    X = prepare_data_lgbm(X)\n",
    "    test_data = prepare_data_lgbm(test_data)\n",
    "\n",
    "best_pipeline.fit(X, y)\n",
    "y_pred_test = best_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create a numeric transformer with imputer and scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=50, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 0.08561272829569276\n",
      "MAPE: 0.07944890426994645\n",
      "MAPE: 0.07684108964408275\n",
      "MAPE: 0.0885103730156893\n",
      "MAPE: 0.07450817040666825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;sin_dayofweek&#x27;,\n",
       "                                                   &#x27;cos_dayofweek&#x27;, &#x27;sin_month&#x27;,\n",
       "                                                   &#x27;cos_month&#x27;, &#x27;sin_year&#x27;,\n",
       "                                                   &#x27;cos_year&#x27;,\n",
       "                                                   &#x27;gdp_per_capita&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;country&#x27;, &#x27;store&#x27;,\n",
       "                                                   &#x27;product&#x27;])])),\n",
       "                (&#x27;regressor&#x27;,\n",
       "                 RandomForestRegressor(n_estimators=50, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;sin_dayofweek&#x27;,\n",
       "                                                   &#x27;cos_dayofweek&#x27;, &#x27;sin_month&#x27;,\n",
       "                                                   &#x27;cos_month&#x27;, &#x27;sin_year&#x27;,\n",
       "                                                   &#x27;cos_year&#x27;,\n",
       "                                                   &#x27;gdp_per_capita&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;country&#x27;, &#x27;store&#x27;,\n",
       "                                                   &#x27;product&#x27;])])),\n",
       "                (&#x27;regressor&#x27;,\n",
       "                 RandomForestRegressor(n_estimators=50, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;sin_dayofweek&#x27;, &#x27;cos_dayofweek&#x27;, &#x27;sin_month&#x27;,\n",
       "                                  &#x27;cos_month&#x27;, &#x27;sin_year&#x27;, &#x27;cos_year&#x27;,\n",
       "                                  &#x27;gdp_per_capita&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;country&#x27;, &#x27;store&#x27;, &#x27;product&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sin_dayofweek&#x27;, &#x27;cos_dayofweek&#x27;, &#x27;sin_month&#x27;, &#x27;cos_month&#x27;, &#x27;sin_year&#x27;, &#x27;cos_year&#x27;, &#x27;gdp_per_capita&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;country&#x27;, &#x27;store&#x27;, &#x27;product&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['sin_dayofweek',\n",
       "                                                   'cos_dayofweek', 'sin_month',\n",
       "                                                   'cos_month', 'sin_year',\n",
       "                                                   'cos_year',\n",
       "                                                   'gdp_per_capita']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['country', 'store',\n",
       "                                                   'product'])])),\n",
       "                ('regressor',\n",
       "                 RandomForestRegressor(n_estimators=50, random_state=42))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for fold_index, (train_index, val_index) in enumerate(time_series.split(X)):\n",
    "    \n",
    "    X_train_fold = X.iloc[train_index]\n",
    "    y_train_fold = y.iloc[train_index]\n",
    "    X_val_fold = X.iloc[val_index]\n",
    "    y_val_fold = y.iloc[val_index]\n",
    "    model_pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    y_pred_val = model_pipeline.predict(X_val_fold)    \n",
    "    mape = mean_absolute_percentage_error(y_val_fold, y_pred_val)\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    \n",
    "model_pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_pipeline.predict(test_data)\n",
    "#submission\n",
    "submission = pd.DataFrame({\"id\": test_data[\"id\"],\"num_sold\":y_pred_test})\n",
    "submission.to_csv(FOLDER + \"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
